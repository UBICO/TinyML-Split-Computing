{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ModelDataGenerator import ModelDataGenerator\n",
    "from ModelBuilder import ModelBuilder\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models/test_model/data', exist_ok=True)\n",
    "os.makedirs('models/test_model/data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of ModelDataGenerator\n",
    "generator = ModelDataGenerator(\n",
    "    image_size=10, \n",
    "    num_images=1000,\n",
    "    dataset_path='models/test_model/data'\n",
    ")\n",
    "\n",
    "# Generate and save the dataset\n",
    "image_paths, labels = generator.generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 1s 11ms/step - loss: 0.2386 - accuracy: 0.9312 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 9.5822e-04 - accuracy: 1.0000 - val_loss: 6.4096e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 4.7754e-04 - accuracy: 1.0000 - val_loss: 3.3290e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.6702e-04 - accuracy: 1.0000 - val_loss: 1.9948e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.6972e-04 - accuracy: 1.0000 - val_loss: 1.3195e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.1631e-04 - accuracy: 1.0000 - val_loss: 9.2896e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 8.3799e-05 - accuracy: 1.0000 - val_loss: 6.7926e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 6.2143e-05 - accuracy: 1.0000 - val_loss: 5.0810e-05 - val_accuracy: 1.0000\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0810e-05 - accuracy: 1.0000\n",
      "Test Loss: 0.0001, Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = ModelBuilder(\n",
    "    image_size=10, \n",
    "    num_classes=1, \n",
    "    image_paths=image_paths, \n",
    "    labels= labels, \n",
    "    dataset_path='models/test_model/data'\n",
    ")\n",
    "model.train_model(epochs=10)\n",
    "model.evaluate_model()\n",
    "model.save_model_as_h5(model_name='test_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step\n",
      "Model predicts a 1\n",
      "values is a 1\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Model does not predict a 1\n",
      "values is a 0\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Model does not predict a 1\n",
      "values is a 0\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Model does not predict a 1\n",
      "values is a 0\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Model predicts a 1\n",
      "values is a 1\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Model predicts a 1\n",
      "values is a 1\n"
     ]
    }
   ],
   "source": [
    "# Get the prediction from the model\n",
    "data_for_predictions  = [\n",
    "    \"./models/test_model/pred_data/pred_test_is_1.png\",\n",
    "    \"./models/test_model/pred_data/pred_test_is_0.png\",\n",
    "    \"./models/test_model/pred_data/pred_test_is_0.png\",\n",
    "    \"./models/test_model/pred_data/pred_test_is_0.png\",\n",
    "    \"./models/test_model/pred_data/pred_test_is_1.png\",\n",
    "    \"./models/test_model/pred_data/pred_test_is_1.png\",\n",
    "]\n",
    "\n",
    "# Set a threshold for classification (you can adjust this based on your needs)\n",
    "threshold = 0.5\n",
    "\n",
    "for data in data_for_predictions:\n",
    "    \n",
    "    prediction = model.predict(data)\n",
    "    # Check if the prediction is greater than the threshold\n",
    "    if prediction[0][0] >= threshold:\n",
    "        print(\"Model predicts a 1\")\n",
    "    else:\n",
    "        print(\"Model does not predict a 1\")\n",
    "    correct_value = data.split('_')[-1].split('.')[0]\n",
    "    print(f\"values is a {correct_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 10, 10, 3), dtype=tf.float32, name='layer_0_input'), name='layer_0_input', description=\"created by layer 'layer_0_input'\") KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 32), dtype=tf.float32, name=None), name='layer_0/Relu:0', description=\"created by layer 'layer_0'\")\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "\n",
      "layer_0, 65536, 65.656494140625\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 32), dtype=tf.float32, name=None), name='layer_0/Relu:0', description=\"created by layer 'layer_0'\") KerasTensor(type_spec=TensorSpec(shape=(None, 4, 4, 32), dtype=tf.float32, name=None), name='layer_1/MaxPool:0', description=\"created by layer 'layer_1'\")\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "\n",
      "layer_1, 16384, 87.31005859375\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 4, 4, 32), dtype=tf.float32, name=None), name='layer_1/MaxPool:0', description=\"created by layer 'layer_1'\") KerasTensor(type_spec=TensorSpec(shape=(None, 512), dtype=tf.float32, name=None), name='layer_2/Reshape:0', description=\"created by layer 'layer_2'\")\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "layer_2, 16384, 69.336181640625\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 512), dtype=tf.float32, name=None), name='layer_2/Reshape:0', description=\"created by layer 'layer_2'\") KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='layer_3/Relu:0', description=\"created by layer 'layer_3'\")\n",
      "WARNING:tensorflow:5 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000017C358EDD00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "\n",
      "layer_3, 2048, 70.70751953125\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='layer_3/Relu:0', description=\"created by layer 'layer_3'\") KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='layer_4/Sigmoid:0', description=\"created by layer 'layer_4'\")\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000017C35B0DE40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "\n",
      "layer_4, 32, 66.17919921875\n",
      "Model does not predict a 1\n",
      "values is a 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import time\n",
    "import csv \n",
    "\n",
    "\n",
    "def calculate_size_in_bits(layer_output):\n",
    "    # Get the data type of the layer output\n",
    "    dtype = layer_output.dtype\n",
    "    # Calculate the size in bits\n",
    "    size_in_bits = tf.reduce_prod(layer_output.shape) * tf.constant(dtype.itemsize * 8)\n",
    "    return size_in_bits.numpy()  # Convert to a Python scalar for writing to CSV\n",
    "\n",
    "def create_analytics_csv(analytics_path, layer_name, layer_size, layer_inference_time):\n",
    "    with open(analytics_path, mode='a', newline='') as csv_file:\n",
    "        fieldnames = ['layer', 'layer_size', 'layer_inference_time']\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "        # Check if the file is empty and write the header if needed\n",
    "        if csv_file.tell() == 0:\n",
    "            writer.writeheader()\n",
    "\n",
    "        writer.writerow({\n",
    "            'layer': layer_name,\n",
    "            'layer_size': layer_size,\n",
    "            'layer_inference_time': layer_inference_time\n",
    "        })\n",
    "    print(f\"\\n{layer_name}, {layer_size}, {layer_inference_time}\")\n",
    "\n",
    "def load_model(model_path='models/test_model/test_model.h5'):\n",
    "    return tf.keras.models.load_model(model_path)\n",
    "\n",
    "def predict_single_layer(model, layer_id, layer_input_data, analytics_path):\n",
    "    layer = model.layers[layer_id]\n",
    "    # Create an intermediate model with the current layer\n",
    "    intermediate_model = tf.keras.Model(inputs=layer.input, outputs=layer.output)\n",
    "    print(layer.input, layer.output)\n",
    "    # Predict using the current layer, keeps track of the time it takes\n",
    "    t_begin = time.time() * 1000\n",
    "    layer_output = intermediate_model.predict(layer_input_data)\n",
    "    t_end = time.time() * 1000\n",
    "\n",
    "    create_analytics_csv(\n",
    "        analytics_path = analytics_path,\n",
    "        layer_name = layer.name,\n",
    "        layer_inference_time = t_end - t_begin,\n",
    "        layer_size = calculate_size_in_bits(layer_output)\n",
    "    )\n",
    "    \n",
    "    return layer_output\n",
    "\n",
    "def perform_predict(model, start_layer_index=0, input_data='', analytics_path=''):\n",
    "    num_layers = len(model.layers)\n",
    "    predictions = []\n",
    "\n",
    "    # Load and preprocess the input image for the first layer\n",
    "    input_image = load_img(input_data, target_size=(10, 10))\n",
    "    input_array = img_to_array(input_image)\n",
    "    input_array = tf.expand_dims(input_array, 0)  # Create batch axis\n",
    "    input_array = input_array / 255.0  # Normalize pixel values to be between 0 and 1\n",
    "\n",
    "    for layer_id in range(start_layer_index, num_layers):\n",
    "        # For the first layer, use the preprocessed input image\n",
    "        if layer_id == 0:\n",
    "            # Resize the input to match the expected shape of the first layer\n",
    "            input_array = tf.image.resize(input_array, (10, 10))\n",
    "            layer_output = predict_single_layer(model, layer_id, input_array, analytics_path)\n",
    "        else:\n",
    "            # For subsequent layers, reshape the output of the previous layer if needed\n",
    "            previous_layer_output = predictions[-1]\n",
    "            expected_input_shape = model.layers[layer_id].input_shape[1:]  # Exclude batch dimension\n",
    "            if previous_layer_output.shape[1:] != expected_input_shape:\n",
    "                previous_layer_output = tf.image.resize(previous_layer_output, expected_input_shape)\n",
    "            layer_output = predict_single_layer(model, layer_id, previous_layer_output, analytics_path)\n",
    "\n",
    "        predictions.append(layer_output)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "model = load_model(model_path='./models/test_model/test_model.h5')\n",
    "input_data = './models/test_model/pred_data/pred_test_is_0.png'\n",
    "analytics_path = './models/test_model/analytics_data/analytics.csv'\n",
    "predictions = perform_predict(model=model, input_data=input_data, analytics_path=analytics_path)\n",
    "prediction = predictions[-1][0]\n",
    "threshold= 0.5\n",
    "# Check if the prediction is greater than the threshold\n",
    "if prediction >= threshold:\n",
    "    print(\"Model predicts a 1\")\n",
    "else:\n",
    "    print(\"Model does not predict a 1\")\n",
    "correct_value = input_data.split('_')[-1].split('.')[0]\n",
    "print(f\"values is a {correct_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
